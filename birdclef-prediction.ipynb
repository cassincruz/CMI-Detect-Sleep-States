{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2314c2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-04T15:15:14.172282Z",
     "iopub.status.busy": "2024-06-04T15:15:14.171417Z",
     "iopub.status.idle": "2024-06-04T15:15:20.143764Z",
     "shell.execute_reply": "2024-06-04T15:15:20.142648Z"
    },
    "papermill": {
     "duration": 5.980126,
     "end_time": "2024-06-04T15:15:20.146328",
     "exception": false,
     "start_time": "2024-06-04T15:15:14.166202",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os \n",
    "from tqdm import tqdm, trange\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import plotly.express as px \n",
    "from IPython.display import Audio\n",
    "\n",
    "import librosa\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.nn import init\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d29775a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-04T15:15:20.154850Z",
     "iopub.status.busy": "2024-06-04T15:15:20.154315Z",
     "iopub.status.idle": "2024-06-04T15:15:20.468297Z",
     "shell.execute_reply": "2024-06-04T15:15:20.467536Z"
    },
    "papermill": {
     "duration": 0.320547,
     "end_time": "2024-06-04T15:15:20.470611",
     "exception": false,
     "start_time": "2024-06-04T15:15:20.150064",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PATHS : \n",
    "    root_path = '/kaggle/input/'\n",
    "    competition_path = os.path.join(root_path, 'birdclef-2024')\n",
    "    enhanced_path = os.path.join(root_path, 'enhanced-birdclef-metadata')\n",
    "    train_audio = os.path.join(competition_path, 'train_audio')\n",
    "    unlabeled_soundscapes = os.path.join(competition_path, 'unlabeled_soundscapes')\n",
    "\n",
    "sample_submission = pd.read_csv(os.path.join(PATHS.competition_path, \"sample_submission.csv\"))\n",
    "taxonomy = pd.read_csv(os.path.join(PATHS.competition_path, \"eBird_Taxonomy_v2021.csv\"))\n",
    "metadata = pd.read_csv(os.path.join(PATHS.enhanced_path, \"enhanced_metadata.csv\"))\n",
    "\n",
    "# Encoding primary_label as numerical label \n",
    "NUM_CATEGORIES = metadata.primary_label.nunique()\n",
    "labels = metadata.primary_label.unique()\n",
    "metadata['nlabel'] = metadata.primary_label.map(dict(zip(labels, range(len(labels)))))\n",
    "\n",
    "#NOTE : Need to fix csv file to remove index column\n",
    "#TODO: Fix csv input\n",
    "metadata = metadata.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ee816e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-04T15:15:20.478717Z",
     "iopub.status.busy": "2024-06-04T15:15:20.478070Z",
     "iopub.status.idle": "2024-06-04T15:15:20.490655Z",
     "shell.execute_reply": "2024-06-04T15:15:20.489778Z"
    },
    "papermill": {
     "duration": 0.018605,
     "end_time": "2024-06-04T15:15:20.492532",
     "exception": false,
     "start_time": "2024-06-04T15:15:20.473927",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_spectrogram(filepath:str, duration=5.0, offset=0.0, pad=True) : \n",
    "    \"\"\"\n",
    "    Generates a mel spectrogram from an audio file.\n",
    "    \n",
    "    filepath: Local path in train_audio/ directory to audio file.\n",
    "    duration: Window length, in seconds\n",
    "    offset: Start time of sample\n",
    "    pad: Whether to pad shorter samples to match duration\n",
    "    \"\"\"\n",
    "    # Retrieving and loading data\n",
    "    data, sr = librosa.load(os.path.join(PATHS.train_audio, filepath), offset=offset, duration=duration)\n",
    "    \n",
    "    # Padding to desired duration\n",
    "    if pad and ((sample_dur := librosa.get_duration(y=data, sr=sr)) < duration) : \n",
    "        data = np.append(data, np.zeros(int((duration - sample_dur) * sr)))\n",
    "    \n",
    "    # Computing stft\n",
    "    stft = librosa.stft(data, n_fft=1024)\n",
    "\n",
    "    # Computing mel spectrogram \n",
    "    specmag, _ = librosa.magphase(stft)\n",
    "    melspec = librosa.feature.melspectrogram(S=specmag, sr=sr)\n",
    "    melspec = librosa.amplitude_to_db(melspec, ref=np.min)\n",
    "    \n",
    "    return melspec\n",
    "\n",
    "def augment_spectrogram(spectrogram, normalize=True, max_noise=0.0, timetranslate=0.0, freqblock=0.0, timeblock=0.0) : \n",
    "    \"\"\"\n",
    "    Augments spectrogram data by normalizing, randomly translating, and/or adding noise.\n",
    "    \"\"\"\n",
    "    \n",
    "    if max_noise : \n",
    "        spectrogram = spectrogram + np.random.random() * max_noise * spectrogram.max() * np.random.random(spectrogram.shape)\n",
    "    \n",
    "    if normalize : \n",
    "        spectrogram = (spectrogram - spectrogram.mean())/spectrogram.std() if spectrogram.std() > 0 else spectrogram - spectrogram.mean()\n",
    "    \n",
    "    # Random translation\n",
    "    if timetranslate : \n",
    "        spectrogram = np.roll(spectrogram, np.random.randint(spectrogram.shape[1]), axis=1)\n",
    "        \n",
    "    if freqblock : \n",
    "        # frequency blocking\n",
    "        start_freq = np.random.randint(0, spectrogram.shape[0])\n",
    "        blocklength = np.random.poisson(freqblock * spectrogram.shape[0])\n",
    "        \n",
    "        spectrogram[start_freq:start_freq+blocklength, :] = 0\n",
    "        \n",
    "    if timeblock :\n",
    "        # time blocking\n",
    "        start_time = np.random.randint(0, spectrogram.shape[1])\n",
    "        blocklength = np.random.poisson(timeblock * spectrogram.shape[1])\n",
    "        \n",
    "        spectrogram[:, start_time:start_time+blocklength] = 0\n",
    "    \n",
    "    return spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7383c49e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-04T15:15:20.499704Z",
     "iopub.status.busy": "2024-06-04T15:15:20.499396Z",
     "iopub.status.idle": "2024-06-04T15:15:20.509840Z",
     "shell.execute_reply": "2024-06-04T15:15:20.508469Z"
    },
    "papermill": {
     "duration": 0.017135,
     "end_time": "2024-06-04T15:15:20.512691",
     "exception": false,
     "start_time": "2024-06-04T15:15:20.495556",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BirdCLEFDataset(Dataset) : \n",
    "    def __init__(self, metadata: pd.DataFrame, window_size=3.0, overlap=0.0, num_categories=NUM_CATEGORIES) : \n",
    "        \"\"\"\n",
    "        metadata: Dataframe containing enhanced sample metadata, including filenames and nlabels\n",
    "        window_size: Duration of samples, in seconds\n",
    "        overlap: Percent of overlap between windows, lying in the range [0, 1)\n",
    "        \"\"\"\n",
    "        self.metadata = metadata\n",
    "        self.window_size = window_size\n",
    "        self.overlap = overlap\n",
    "        self.num_categories = num_categories\n",
    "        \n",
    "        # Get cumulative number of samples per recording\n",
    "        self.n_samples = np.ceil(self.metadata.duration / (self.window_size * (1.0 - self.overlap))).cumsum()\n",
    "        \n",
    "    def __len__(self) : \n",
    "        return int(self.n_samples.iloc[-1])\n",
    "    \n",
    "    def __getitem__(self, idx) : \n",
    "        \n",
    "        # Find which recording the idx corresponds to\n",
    "        data_loc = np.where(self.n_samples >= idx+1)[0].min()\n",
    "        audio_path = os.path.join(PATHS.train_audio, self.metadata.filename.iloc[data_loc])\n",
    "        \n",
    "        # Get location within recording\n",
    "        i = int(idx - ([0.0] + self.n_samples.to_list())[data_loc])\n",
    "        \n",
    "        # Load sample\n",
    "        sample = augment_spectrogram(get_spectrogram(audio_path, offset=i*(self.window_size * (1.0 - self.overlap)), duration=self.window_size), max_noise=1.0, freqblock=0.1, timeblock=0.05)\n",
    "        X = torch.Tensor(sample)\n",
    "        \n",
    "        # Get label\n",
    "        nlabel = self.metadata.nlabel.iloc[data_loc]\n",
    "        y = F.one_hot(torch.as_tensor(nlabel), num_classes=self.num_categories).type(torch.float32)\n",
    "        \n",
    "        return X, y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3641c1c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-04T15:15:20.521200Z",
     "iopub.status.busy": "2024-06-04T15:15:20.520896Z",
     "iopub.status.idle": "2024-06-04T15:15:20.558242Z",
     "shell.execute_reply": "2024-06-04T15:15:20.557456Z"
    },
    "papermill": {
     "duration": 0.044184,
     "end_time": "2024-06-04T15:15:20.560584",
     "exception": false,
     "start_time": "2024-06-04T15:15:20.516400",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "metadata_hq = metadata[metadata.rating >= 3.0]\n",
    "\n",
    "train_metadata, val_metadata = train_test_split(metadata_hq, test_size=0.2, random_state=42, stratify=metadata_hq.nlabel)\n",
    "\n",
    "train = BirdCLEFDataset(train_metadata, window_size=4.0, overlap=0.0)\n",
    "val = BirdCLEFDataset(val_metadata, window_size=4.0, overlap=0.5)\n",
    "\n",
    "train_loader = DataLoader(train, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b38d6665",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-04T15:15:20.568454Z",
     "iopub.status.busy": "2024-06-04T15:15:20.568171Z",
     "iopub.status.idle": "2024-06-04T15:15:20.581138Z",
     "shell.execute_reply": "2024-06-04T15:15:20.580415Z"
    },
    "papermill": {
     "duration": 0.018999,
     "end_time": "2024-06-04T15:15:20.582959",
     "exception": false,
     "start_time": "2024-06-04T15:15:20.563960",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BirdClassifier_1DCNN (nn.Module) : \n",
    "    \n",
    "    def __init__(self, num_categories=NUM_CATEGORIES) : \n",
    "        super().__init__()\n",
    "        conv_layers = []\n",
    "\n",
    "        # First Convolution Block with Relu and Batch Norm.\n",
    "        self.conv1 = nn.Conv1d(128, 256, kernel_size=10, stride=2, padding=2)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.bn1 = nn.BatchNorm1d(256)\n",
    "        self.conv1.bias.data.zero_()\n",
    "        conv_layers += [self.conv1, self.relu1, self.bn1]\n",
    "\n",
    "        # Second Convolution Block\n",
    "        self.conv2 = nn.Conv1d(256, 256, kernel_size=10, stride=2, padding=2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.conv2.bias.data.zero_()\n",
    "        conv_layers += [self.conv2, self.relu2, self.bn2]\n",
    "\n",
    "        # Third Convolution Block\n",
    "        self.conv3 = nn.Conv1d(256, 128, kernel_size=5, stride=2, padding=2)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.conv3.bias.data.zero_()\n",
    "        conv_layers += [self.conv3, self.relu3, self.bn3]\n",
    "\n",
    "        # Fourth Convolution Block\n",
    "        self.conv4 = nn.Conv1d(128, 64, kernel_size=5, stride=2, padding=2)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.bn4 = nn.BatchNorm1d(64)\n",
    "        self.conv4.bias.data.zero_()\n",
    "        conv_layers += [self.conv4, self.relu4, self.bn4]\n",
    "\n",
    "        # Linear Classifier\n",
    "        # in_features = 64 * 26 for 5 secs, 1344 for 4 sec, and 1024 for 3 sec inputs\n",
    "        self.lin = nn.Linear(in_features=1344, out_features=num_categories)\n",
    "\n",
    "        # Wrap the Convolutional Blocks\n",
    "        self.conv = nn.Sequential(*conv_layers)\n",
    "    \n",
    "    # ----------------------------\n",
    "    # Forward pass computations\n",
    "    # ----------------------------\n",
    "    def forward(self, x):\n",
    "        # Run the convolutional blocks\n",
    "        x = self.conv(x)\n",
    "\n",
    "        # Flatten for input to linear layer\n",
    "        x = x.view(x.shape[0], -1)\n",
    "\n",
    "        # Linear layer\n",
    "        x = self.lin(x)\n",
    "\n",
    "        # Final output\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bd0c095",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-04T15:15:20.589890Z",
     "iopub.status.busy": "2024-06-04T15:15:20.589618Z",
     "iopub.status.idle": "2024-06-04T18:01:51.967216Z",
     "shell.execute_reply": "2024-06-04T18:01:51.966011Z"
    },
    "papermill": {
     "duration": 9992.358225,
     "end_time": "2024-06-04T18:01:52.944117",
     "exception": false,
     "start_time": "2024-06-04T15:15:20.585892",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model running on cuda.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 3.93, Correct: 4.8%: 100%|██████████| 5889/5889 [2:46:28<00:00,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as model_240604.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Define model and loss criterion\n",
    "model = BirdClassifier_1DCNN()\n",
    "\n",
    "# Optional: Load model from persistent storage\n",
    "#model.load_state_dict(torch.load('model_240515.pt'))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Send to device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model.to(device)\n",
    "\n",
    "print(f\"Model running on {device}.\")\n",
    "\n",
    "# Train the model\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "#for epoch in range(5):  \n",
    "for i, (X, y) in enumerate(pbar := tqdm(train_loader)):\n",
    "    X, y = X.to(device), y.to(device)\n",
    "    # Zero the gradients\n",
    "    optimizer.zero_grad()\n",
    "    # Forward pass \n",
    "    outputs = model(X)\n",
    "    # Compute the loss\n",
    "    loss = criterion(outputs, y)\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    # Update the model parameters\n",
    "    optimizer.step() \n",
    "    \n",
    "    #print(\"Output:\" + \", \".join([colored(output, 'green' if output == y.argmax(axis=1)[i] else 'red') for i, output in enumerate(outputs.argmax(axis=1).detach().tolist())]))\n",
    "    pbar.set_description(f'Loss: {loss.item():.2f}, Correct: {100 * (y.argmax(axis=1) == outputs.argmax(axis=1)).sum()/y.shape[0]:.1f}%')\n",
    "    \n",
    "    if i % 100 == 0 : \n",
    "        torch.save(model.state_dict(), modelname:=f\"model_{datetime.now().strftime('%y%m%d')}.pt\")\n",
    "\n",
    "print(f\"Model saved as {modelname}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 8068726,
     "sourceId": 70203,
     "sourceType": "competition"
    },
    {
     "datasetId": 4900318,
     "sourceId": 8257073,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30684,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 10004.984396,
   "end_time": "2024-06-04T18:01:56.414847",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-06-04T15:15:11.430451",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
